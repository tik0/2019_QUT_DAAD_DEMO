{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This script demonstrates VAE on image data\n",
    "\n",
    " #Reference\n",
    "\n",
    " - Auto-Encoding Variational Bayes\n",
    "   https://arxiv.org/abs/1312.6114\n",
    " - Joint Multi-Modal VAE\n",
    "   https://arxiv.org/pdf/1611.01891.pdf\n",
    "'''\n",
    "import warnings\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.mlab as mlab\n",
    "plt.rcParams[\"figure.figsize\"] = [20,20]\n",
    "from scipy.stats import norm\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer, LeakyReLU, BatchNormalization\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import keras\n",
    "from skimage.transform import resize\n",
    "from PIL import Image\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.expanduser('/opt/repositories/twbserver_notebook/notebook/tools'))\n",
    "import vae_tools\n",
    "from vae_tools import plot_model, layers, nb_tools, viz, loader, build_model, sanity, sampling, custom_variational_layer\n",
    "\n",
    "nb_tools.notebook_resize()\n",
    "sanity.check()\n",
    "\n",
    "data_set_size = 1710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(data_set = 'img_0', batch_size = 1, shuffle=False):\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        horizontal_flip=False,\n",
    "        width_shift_range=0.0,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.0)  # randomly shift images vertically (fraction of total height))\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(data_set, interpolation='nearest',\n",
    "            color_mode='rgb', shuffle=shuffle, seed=None,\n",
    "            target_size=(48, 64),\n",
    "            batch_size=batch_size,\n",
    "            #save_to_dir='img_0_augmented',\n",
    "            class_mode=None)\n",
    "    return train_generator\n",
    "\n",
    "X_train_0 = get_iterator(data_set = 'img_0', batch_size = data_set_size).next()\n",
    "X_train_1 = get_iterator(data_set = 'img_pitch_pi2', batch_size = data_set_size).next()\n",
    "X_train_2 = get_iterator(data_set = 'img_pitch_-pi2', batch_size = data_set_size).next()\n",
    "X_train_3 = get_iterator(data_set = 'img_roll_pi', batch_size = data_set_size).next()\n",
    "X_train_4 = get_iterator(data_set = 'img_roll_pi2', batch_size = data_set_size).next()\n",
    "X_train_5 = get_iterator(data_set = 'img_roll_-pi2', batch_size = data_set_size).next()\n",
    "\n",
    "# Stack the set\n",
    "X_train = np.concatenate((X_train_0, X_train_1, X_train_2, X_train_3, X_train_4, X_train_5), axis=0)\n",
    "# reshape from (: 48, 64, 3) to (:, 64, 64, 3)\n",
    "X_train = np.concatenate((X_train, np.repeat(X_train[:, [-1], :, :], 8, axis = 1)), axis = 1)\n",
    "X_train = np.concatenate((np.repeat(X_train[:, [0], :, :], 8, axis = 1), X_train), axis = 1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some scaled and squared image\n",
    "x = get_iterator(shuffle = True, batch_size = 10).next()\n",
    "# make it square\n",
    "x = np.concatenate((x, np.repeat(x[:, [-1], :, :], 8, axis = 1)), axis = 1)\n",
    "x = np.concatenate((np.repeat(x[:, [0], :, :], 8, axis = 1), x), axis = 1)\n",
    "print(x[0].shape)\n",
    "plt.imshow(x[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions and config\n",
    "batch_size = 64\n",
    "n_channels = 3\n",
    "image_rows_cols_chns = (64, 64, n_channels)\n",
    "original_dim = np.prod(image_rows_cols_chns)\n",
    "img_chns = image_rows_cols_chns[2]\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    original_img_size = (image_rows_cols_chns[2], image_rows_cols_chns[0], image_rows_cols_chns[1])\n",
    "else:\n",
    "    original_img_size = image_rows_cols_chns\n",
    "latent_dim = 2\n",
    "epochs = 4000\n",
    "save_model = False\n",
    "#beta = 0.012207031 # 50.\n",
    "beta = 1.\n",
    "n_encoder = 1024\n",
    "latent_dim = 128\n",
    "decode_from_shape = (8, 8, 256)\n",
    "n_decoder = np.prod(decode_from_shape)\n",
    "leaky_relu_alpha = 0.2\n",
    "recon_depth=9\n",
    "wdecay=1e-5\n",
    "bn_mom=0.9\n",
    "bn_eps=1e-6\n",
    "\n",
    "def conv_block(x, filters, leaky=True, transpose=False, name=''):\n",
    "    conv = Conv2DTranspose if transpose else Conv2D\n",
    "    activation = LeakyReLU(leaky_relu_alpha) if leaky else Activation('relu')\n",
    "    layers = [\n",
    "        conv(filters, 5, strides=2, padding='same', kernel_regularizer=l2(wdecay), kernel_initializer='he_uniform', name=name + 'conv'),\n",
    "        BatchNormalization(momentum=bn_mom, epsilon=bn_eps, name=name + 'bn'),\n",
    "        activation\n",
    "    ]\n",
    "    if x is None:\n",
    "        return layers\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n",
    "encoder = [[\n",
    "    Input(shape=original_img_size),\n",
    "    *conv_block(None, 64, name='enc_blk_1_'),\n",
    "    *conv_block(None, 128, name='enc_blk_2_'),\n",
    "    *conv_block(None, 256, name='enc_blk_3_'),\n",
    "    Flatten(),\n",
    "    Dense(n_encoder, kernel_regularizer=l2(wdecay), kernel_initializer='he_uniform', name='enc_h_dense'),\n",
    "    BatchNormalization(name='enc_h_bn'),\n",
    "    LeakyReLU(leaky_relu_alpha)\n",
    "]]\n",
    "\n",
    "decoder = [[\n",
    "    Dense(n_decoder, kernel_regularizer=l2(wdecay), kernel_initializer='he_uniform', input_shape=(latent_dim,), name='dec_h_dense'),\n",
    "    BatchNormalization(name='dec_h_bn'),\n",
    "    LeakyReLU(leaky_relu_alpha),\n",
    "    Reshape(decode_from_shape),\n",
    "    *conv_block(None, 256, transpose=True, name='dec_blk_1_'),\n",
    "    *conv_block(None, 128, transpose=True, name='dec_blk_2_'),\n",
    "    *conv_block(None, 32, transpose=True, name='dec_blk_3_'),\n",
    "    Conv2D(n_channels, 5, activation='tanh', padding='same', kernel_regularizer=l2(wdecay), kernel_initializer='he_uniform', name='dec_output')\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = vae_tools.mmvae.MmVae(latent_dim, encoder, decoder, [original_dim], beta, beta_is_normalized = False, reconstruction_loss_metrics = [vae_tools.mmvae.ReconstructionLoss.MSE], name='Vae')\n",
    "vae = model_obj.get_model()\n",
    "vae.compile(optimizer='rmsprop', loss=None)\n",
    "vae_tools.viz.plot_model(vae, file = 'myVAE', print_svg = False, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some examples\n",
    "#viz.random_images_from_set(X_set, image_rows_cols_chns, n = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "vae.fit(X_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the model\n",
    "if use_conv:\n",
    "    model_obj.store_model(\"cameraRGB_conv_encoder_mean\", model = model_obj.get_encoder_mean([encoder[0][0]]), overwrite = save_model)\n",
    "else:\n",
    "    model_obj.store_model(\"cameraRGB_encoder_mean\", model = model_obj.get_encoder_mean([encoder[0][0]]), overwrite = save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import vae_tools\n",
    "from importlib import reload\n",
    "reload(vae_tools)\n",
    "\n",
    "# Vizualization\n",
    "# Encode samples to get the min and max values in latent space\n",
    "x_test_encoded = model_obj.get_encoder_mean([encoder[0][0]]).predict(X_train, batch_size=batch_size)\n",
    "\n",
    "# display a 2D manifold\n",
    "nx = 20\n",
    "ny = 20\n",
    "\n",
    "## linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
    "## to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
    "grid_x = norm.ppf(np.linspace(0.001, 0.999, nx))\n",
    "grid_y = norm.ppf(np.linspace(0.001, 0.999, ny))\n",
    "grid_x = np.linspace(np.amin(grid_x), np.amax(grid_x), nx)\n",
    "grid_y = np.linspace(np.amin(grid_y), np.amax(grid_y), ny)\n",
    "grid_x = np.linspace(np.amin(x_test_encoded[:, 0]), np.amax(x_test_encoded[:, 0]), nx)\n",
    "grid_y = np.linspace(np.amin(x_test_encoded[:, 1]), np.amax(x_test_encoded[:, 1]), ny)\n",
    "\n",
    "# display a 2D plot of the digit classes in the latent space\n",
    "import vae_tools\n",
    "from importlib import reload  # Python 3.4+ only.\n",
    "viz = reload(vae_tools.viz)\n",
    "vae_tools.viz.scatter_encoder(X_train, np.zeros((len(X_train),3)), grid_x, grid_y, model_obj, figsize=(15, 15), dpi=150)\n",
    "\n",
    "# Plot the resampled inputs\n",
    "figure, x_mean_test_encoded, x_std_test_encoded = viz.get_image_dec_enc_samples(grid_x, grid_y, model_obj, image_rows_cols_chns)\n",
    "plt.figure(figsize=(15, 15), dpi=96)\n",
    "plt.imshow(figure, cmap='Greys_r')\n",
    "plt.show()\n",
    "\n",
    "# Plot the resampled std deviations\n",
    "X, Y = np.meshgrid(np.arange(0,len(grid_x)), np.arange(0,len(grid_y)))\n",
    "plt.pcolor(X, Y, x_std_test_encoded, cmap='coolwarm', vmin=x_std_test_encoded.min(), vmax=x_std_test_encoded.max())\n",
    "plt.colorbar()\n",
    "plt.axis(\"image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((len(X_train),1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "693px",
    "left": "1442.97px",
    "right": "20px",
    "top": "172.969px",
    "width": "359px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
